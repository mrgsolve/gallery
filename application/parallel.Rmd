---
title: mrgsolve in Parallel
author: "Kyle Baron"
date: "`r Sys.time()`"
output:
  github_document:
    toc: TRUE
---

```{r, echo = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, 
                      comment = '.', fig.path = "img/parallel")
```

# About
This vignette looks at options for parallelizing simulations
with mrgsolve in a platform-independent way.  We utilize the 
`future.apply` package (available on CRAN) to do this.

Your mileage may vary in terms of speedup factor.  It is highly dependent
on the problem you have.  Also, with any method there is some overhead
that needs to be taken into consideration when planning the simulations.  It 
is very possible that your parallelized setup takes __longer__ with the 
non-parallel setup.

# An example model

```{r}
library(dplyr)
library(mrgsolve)
mod <- mread("pk1", modlib())
```

# The `future.apply` package
```{r}
library(future.apply)
Sys.setenv(R_FUTURE_FORK_ENABLE=TRUE)
```


## Simulate with `future_lapply`

Works pretty much like `lapply`

```{r}
plan("multiprocess")
```

Note: with `plan(multiprocess)`, you have to load the model shared
object into the process. See `?laodso`. 

```{r}
e <- ev(amt = 100)
end <- 24

out <- future_lapply(1:10, function(i) {
  
  loadso(mod) ## NOTE
  
  mod %>% 
    ev(e) %>%
    mrgsim(end = end) %>% 
    mutate(i = i)
  
}) %>% bind_rows
```

```{r}
head(out)
```


On macos or unix systems, you can use:
```{r}
plan("multicore", workers=8)
```

```{r}
out <- future_lapply(1:10, function(i) {
  mod %>% 
    ev(amt = 100) %>%
    mrgsim() %>% 
    mutate(i = i)
}) %>% bind_rows
```

```{r}
head(out)
```



# Compare methods

## `future_lapply`

```{r}

plan("multicore", workers=8)

system.time({
  out <- future_lapply(1:2000, function(i) {
    mod %>% 
      ev(amt = 100, ii = 24, addl = 27) %>%
      mrgsim(end = 28*24, nid = 20) %>% 
      mutate(i = i)
  }) %>% bind_rows
})
```

## `lapply`

```{r}
system.time({
  out <- lapply(1:2000, function(i) {
    mod %>% 
      ev(amt = 100, ii = 24, addl = 27) %>%
      mrgsim(end = 28*24, nid = 20) %>% 
      mutate(i = i)
  }) %>% bind_rows
})
```

## `mclapply`

```{r}
options(mc.cores=8)
system.time({
  out <- parallel::mclapply(1:2000, function(i) {
    mod %>% 
      ev(amt = 100, ii = 24, addl = 27) %>%
      mrgsim(end = 28*24, nid = 20) %>% 
      mutate(i = i)
  }) %>% bind_rows
})
```

# Parallelize within data set
 
In this example, let's simulate 3k subjects at each of 8 doses. We'll 
split the data set on the dose and simulate each dose separately and then 
bind back together in a single data set.  This is probably the quickest
way to get it done.  But we really need to work to see the 
speedup from parallelizing.

```{r}
data <- expand.ev(
  ID = seq(2000), 
  amt = c(1,3,10,30,100,300,1000,3000),
  ii = 24, addl = 27
) 
count(data,amt)
```

```{r}
data_split <- split(data, data$amt)

system.time({
  out <- future_lapply(data_split, function(chunk) {
    mod %>% mrgsim_d(chunk, end = 24*27) %>% as_tibble()
  }) %>% bind_rows()
})
```
```{r}
dim(out)
```

```{r}
system.time({
  out <- lapply(data_split, function(chunk) {
    mod %>% mrgsim_d(chunk, end = 24*27) %>% as_tibble()
  }) %>% bind_rows()
})
```



